{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!unzip dataset.zip"
      ],
      "metadata": {
        "id": "3BwATfFdsfpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def load_img(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img,(224,224))\n",
        "    img = np.reshape(img,(1,224,224))\n",
        "    img = img.astype(\"float32\")/255\n",
        "    return img\n",
        "\n",
        "classify_list = ['8PSK','BPSK' ,'PAM4' ,'QAM16','QAM64','QPSK']\n",
        "\n",
        "def load_dataset():\n",
        "    # train:val 8:2 也就是40:10\n",
        "    dataset_path = './dataset/'\n",
        "    classes = os.listdir(dataset_path)\n",
        "    classify = {\n",
        "        '8PSK' :0,\n",
        "        'BPSK' :1,\n",
        "        'PAM4' :2,\n",
        "        'QAM16':3,\n",
        "        'QAM64':4,\n",
        "        'QPSK' :5,\n",
        "        }\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "    for clazz in classes:\n",
        "        img_dir = dataset_path+clazz+'/'\n",
        "        imgs = os.listdir(img_dir)\n",
        "        group = dict()\n",
        "        print(f'loading gorup:{clazz}...')\n",
        "        for name in imgs:\n",
        "            dB = int(name.split('dB')[0])\n",
        "            if group.__contains__(dB):\n",
        "                group[dB].append(name)\n",
        "            else:\n",
        "                group[dB] = [name]\n",
        "        for dB,img_ns in group.items():\n",
        "            img_train = img_ns[:40]\n",
        "            img_test = img_ns[-10:-5]\n",
        "            for img_p in img_train:\n",
        "                img = load_img(img_dir + img_p)\n",
        "                x_train.append(img)\n",
        "                y_train.append(classify[clazz])\n",
        "                # 数据增强\n",
        "                if dB >= 10 :\n",
        "                    tmp = np.flip(img,1)\n",
        "                    x_train.append(tmp)\n",
        "                    y_train.append(classify[clazz])\n",
        "                    tmp = np.flip(tmp,2)\n",
        "                    x_train.append(tmp)\n",
        "                    y_train.append(classify[clazz])\n",
        "                    tmp = np.flip(tmp,1)\n",
        "                    x_train.append(tmp)\n",
        "                    y_train.append(classify[clazz])\n",
        "\n",
        "            for img_p in img_test:\n",
        "                img = load_img(img_dir + img_p)\n",
        "                x_test.append(img)\n",
        "                y_test.append(classify[clazz])\n",
        "    x_train = np.stack(x_train)\n",
        "    y_train = np.reshape(y_train,(len(y_train),1))\n",
        "    x_test = np.stack(x_test)\n",
        "    y_test = np.reshape(y_test,(len(y_test),1))\n",
        "    return (x_train,y_train),(x_test,y_test)"
      ],
      "metadata": {
        "id": "nRwDv2rjzwfY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_val,y_val) = load_dataset()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opYUTF64z33Z",
        "outputId": "cbc6d2e9-89ef-4d6b-9790-5f4bae9d39ce"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading gorup:BPSK...\n",
            "loading gorup:QPSK...\n",
            "loading gorup:PAM4...\n",
            "loading gorup:QAM64...\n",
            "loading gorup:QAM16...\n",
            "loading gorup:8PSK...\n",
            "(6000, 1, 224, 224)\n",
            "(6000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_dataset = NumpyDataset(x_test,y_test)\n",
        "k,v = validate_dataset.__getitem__(0)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0X8XQL09uoE",
        "outputId": "5d431aa1-2281-4ad9-e7a0-1f720f47f251"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 224, 224])\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhp6tP251Nic",
        "outputId": "f5080c00-e8a2-4728-d482-e34722531db2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Author https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/blob/master/pytorch_classification/Test2_alexnet/\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000, init_weights=False):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 48, kernel_size=11, stride=4, padding=2),  # input[1, 224, 224]  output[48, 55, 55]\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27]\n",
        "            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]\n",
        "            nn.Conv2d(128, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(192, 192, kernel_size=3, padding=1),          # output[192, 13, 13]\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(192, 128, kernel_size=3, padding=1),          # output[128, 13, 13]\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(128 * 6 * 6, 2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(2048, 2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2048, num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "Y3S3671P0K--"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NumpyDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 将 NumPy 数组转换为 PyTorch 张量\n",
        "        image = torch.from_numpy(self.data[idx])\n",
        "        label = torch.from_numpy(self.labels[idx])\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "yXbGRKaT543E"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,sys,json\n",
        "\n",
        "from torchvision import transforms, datasets, utils\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"using {} device.\".format(device))\n",
        "\n",
        "    # TOOD\n",
        "    train_dataset = NumpyDataset(x_train,y_train)\n",
        "    train_num = len(train_dataset)\n",
        "\n",
        "    # # {'daisy':0, 'dandelion':1, 'roses':2, 'sunflower':3, 'tulips':4}\n",
        "    # flower_list = train_dataset.class_to_idx\n",
        "    # cla_dict = dict((val, key) for key, val in flower_list.items())\n",
        "    # # write dict into json file\n",
        "    # json_str = json.dumps(cla_dict, indent=4)\n",
        "    # with open('class_indices.json', 'w') as json_file:\n",
        "    #     json_file.write(json_str)\n",
        "\n",
        "    batch_size = 32\n",
        "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
        "    print('Using {} dataloader workers every process'.format(nw))\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True,num_workers=nw)\n",
        "\n",
        "    # TODO\n",
        "    validate_dataset = NumpyDataset(x_val,y_val)\n",
        "\n",
        "    val_num = len(validate_dataset)\n",
        "    validate_loader = torch.utils.data.DataLoader(validate_dataset,batch_size=4, shuffle=False,num_workers=nw)\n",
        "\n",
        "    print(\"using {} images for training, {} images for validation.\".format(train_num,val_num))\n",
        "\n",
        "    net = AlexNet(num_classes=6, init_weights=True)\n",
        "\n",
        "    net.to(device)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    # pata = list(net.parameters())\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.0002)\n",
        "\n",
        "    epochs = 10\n",
        "    save_path = './AlexNet2.pth'\n",
        "    best_acc = 0.0\n",
        "    train_steps = len(train_loader)\n",
        "    for epoch in range(epochs):\n",
        "        # train\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            labels = labels.squeeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images.to(device))\n",
        "            # print(f'output={outputs.shape},labes={labels.shape}')\n",
        "            loss = loss_function(outputs, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1,epochs,loss)\n",
        "\n",
        "        # validate\n",
        "        net.eval()\n",
        "        acc = 0.0  # accumulate accurate number / epoch\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(validate_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                val_labes = val_labels.squeeze(1)\n",
        "                outputs = net(val_images.to(device))\n",
        "                predict_y = torch.max(outputs, dim=1)[1]\n",
        "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
        "\n",
        "        val_accurate = acc / val_num / validate_loader.batch_size\n",
        "        print('[epoch %d] train_loss: %.3f  val_accuracy: %.3f ' %\n",
        "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
        "\n",
        "        if val_accurate > best_acc:\n",
        "            best_acc = val_accurate\n",
        "            torch.save(net.state_dict(), save_path)\n",
        "\n",
        "    print('Finished Training')\n"
      ],
      "metadata": {
        "id": "YCALz5Ik1k4X"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJn0qIO37uof",
        "outputId": "1be102f9-6708-497d-a307-886d4305d43f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda:0 device.\n",
            "Using 2 dataloader workers every process\n",
            "using 6000 images for training, 300 images for validation.\n",
            "train epoch[1/10] loss:0.594: 100%|██████████| 188/188 [00:04<00:00, 40.23it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 121.67it/s]\n",
            "[epoch 1] train_loss: 1.319  val_accuracy: 0.657 \n",
            "train epoch[2/10] loss:0.746: 100%|██████████| 188/188 [00:04<00:00, 43.05it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 186.55it/s]\n",
            "[epoch 2] train_loss: 0.601  val_accuracy: 0.718 \n",
            "train epoch[3/10] loss:0.823: 100%|██████████| 188/188 [00:04<00:00, 43.54it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 178.14it/s]\n",
            "[epoch 3] train_loss: 0.473  val_accuracy: 0.767 \n",
            "train epoch[4/10] loss:0.292: 100%|██████████| 188/188 [00:04<00:00, 37.86it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 190.67it/s]\n",
            "[epoch 4] train_loss: 0.391  val_accuracy: 0.800 \n",
            "train epoch[5/10] loss:0.385: 100%|██████████| 188/188 [00:04<00:00, 43.79it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 184.58it/s]\n",
            "[epoch 5] train_loss: 0.340  val_accuracy: 0.797 \n",
            "train epoch[6/10] loss:0.398: 100%|██████████| 188/188 [00:04<00:00, 40.78it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 125.43it/s]\n",
            "[epoch 6] train_loss: 0.325  val_accuracy: 0.818 \n",
            "train epoch[7/10] loss:0.284: 100%|██████████| 188/188 [00:04<00:00, 43.34it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 186.60it/s]\n",
            "[epoch 7] train_loss: 0.287  val_accuracy: 0.780 \n",
            "train epoch[8/10] loss:0.446: 100%|██████████| 188/188 [00:04<00:00, 44.10it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 186.44it/s]\n",
            "[epoch 8] train_loss: 0.275  val_accuracy: 0.802 \n",
            "train epoch[9/10] loss:0.309: 100%|██████████| 188/188 [00:04<00:00, 37.78it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 185.29it/s]\n",
            "[epoch 9] train_loss: 0.235  val_accuracy: 0.823 \n",
            "train epoch[10/10] loss:0.407: 100%|██████████| 188/188 [00:04<00:00, 44.03it/s]\n",
            "100%|██████████| 75/75 [00:00<00:00, 190.39it/s]\n",
            "[epoch 10] train_loss: 0.213  val_accuracy: 0.797 \n",
            "Finished Training\n"
          ]
        }
      ]
    }
  ]
}